from pathlib import Path
import argparse
import json
import os
import random
import signal
import sys
import time
import urllib

from torch import nn, optim
from torchvision import models, datasets, transforms
import torch

parser.add_argument('--checkpoint-dir', default='./checkpoint/lincls/', type=Path,
                    metavar='DIR', help='path to checkpoint directory')
parser.add_argument('--pretrained', type=Path, metavar='FILE',default='/mnt/B012D7F812D7C210/HSXcode/NN/barlowtwins-main/checkpoint/resnet50.pth',
                    help='path to pretrained model')                    
def main():
    args = parser.parse_args()
    if args.train_percent in {1, 10}:
        args.train_files = urllib.request.urlopen(f'https://raw.githubusercontent.com/google-research/simclr/master/imagenet_subsets/{args.train_percent}percent.txt').readlines()
    args.ngpus_per_node = torch.cuda.device_count()#自定义的 并非是容器中的数
    if 'SLURM_JOB_ID' in os.environ:
        signal.signal(signal.SIGUSR1, handle_sigusr1)
        signal.signal(signal.SIGTERM, handle_sigterm)
    # single-node distributed training
    args.rank = 0
    args.dist_url = f'tcp://localhost:{random.randrange(49152, 65535)}'
    args.world_size = args.ngpus_per_node #world_size设置为gpu的个数
    torch.multiprocessing.spawn(main_worker, (args,), args.ngpus_per_node)
 
 
def main_worker(gpu, args):
    args.rank += gpu
    #初始化
    torch.distributed.init_process_group(
        backend='nccl', init_method=args.dist_url,
        world_size=args.world_size, rank=args.rank)
        
    #判断 并且创建一个文件夹
    if args.rank == 0:
        args.checkpoint_dir.mkdir(parents=True, exist_ok=True) #args.checkpoint_dir.mkdir
        stats_file = open(args.checkpoint_dir / 'stats.txt', 'a', buffering=1)
        print(' '.join(sys.argv))
        print(' '.join(sys.argv), file=stats_file)

    torch.cuda.set_device(gpu)
    
    
    model = models.resnet50().cuda(gpu)
    #加载模型
    state_dict = torch.load(args.pretrained, map_location='cpu')



    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False) 
    #pth  layer weight bias
    assert missing_keys == ['fc.weight', 'fc.bias'] and unexpected_keys == []
    model.fc.weight.data.normal_(mean=0.0, std=0.01) #通过 model.{bias,fc,cn}.data等方法获取模型中的参数
    model.fc.bias.data.zero_()
    
    #判断模型参数是否冻结 如果冻结 则对模型使用requires_grad_(False)
    if args.weights == 'freeze':
        model.requires_grad_(False)
        model.fc.requires_grad_(True)
     #计算模型内各个模块的参数以及名称
    classifier_parameters, model_parameters = [], []
    for name, param in model.named_parameters():
        if name in {'fc.weight', 'fc.bias'}:
            classifier_parameters.append(param)
        else:
            model_parameters.append(param)
    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])
    
 
    criterion = nn.CrossEntropyLoss().cuda(gpu)

    param_groups = [dict(params=classifier_parameters, lr=args.lr_classifier)]
    if args.weights == 'finetune':
        param_groups.append(dict(params=model_parameters, lr=args.lr_backbone))
    optimizer = optim.SGD(param_groups, 0, momentum=0.9, weight_decay=args.weight_decay)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)

    # automatically resume from checkpoint if it exists
    if (args.checkpoint_dir / 'checkpoint.pth').is_file(): #判断某个文件夹下是否存在文件则使用is_file(),pth文件中存放的是字典格式
        ckpt = torch.load(args.checkpoint_dir / 'checkpoint.pth',
                          map_location='cpu')
        start_epoch = ckpt['epoch']
        best_acc = ckpt['best_acc']
        model.load_state_dict(ckpt['model'])
        optimizer.load_state_dict(ckpt['optimizer'])
        scheduler.load_state_dict(ckpt['scheduler'])
    else:
        start_epoch = 0
        best_acc = argparse.Namespace(top1=0, top5=0)
 
 
 
 
 
